AWS Developer Asociate
-------------------------


IAM
=======================
-Helps to manage users and level of access.
-Centralized control of the AWS account.
-supports MFA
*User
 -Individual who have been granted permssion to AWS account.
 -Each user has username , password and access to various resources.
*Group
 -Group of users with common set of permissions.
*Role
 -temporary permission to a perticular resuource.
*Policy
 -Document that defines one or more permissions.
*Policy Simulator
 -Test the policy.
*Web Identity Federation
*Cognito
*Inline Policy vs Managed Policy


S3
=======================
-Object Based Storage
-Unlimited storage but one object can be from range 0-5 TB
-OS and DB can not be stored.
-Universal namespace. and each bucket name must be globally unique.
-S3 url - https://BUCKET_NAME.s3.Region.amazonaws.com/KEY_NAME
-S3 is highly available and durable. 99.95-99.99 availablity and 11 9s durability.



*S3 Storage Classes
-Standard - High availablity and Durability and high cost. Data is stored across >=3 AZ, Default class and best for frequent access data.Bigdata workloads websites etc
-Standard IA- Best for Infrequent Access and designed as Rapid access.Backups diaster recovery etc. Min days is 30days. 
-One Zone IA - Stored in One zone. 20% less cost then Standard IA. 99.95 availablity.
-S3 Glacier Flexible access
-S3 Glacier Instant access
-S3 Deep Archive
-Intelligent Tiering


*Securing S3 Buckets
*S3 Encryption
*CORS
*Cloudfront
*Athena



EC2
=======================




RDS
=======================


DynamoDB
=======================
-Made up of tables contains items and attributes
-supports JSON,HTML,XML
-Primary Key
	-Partition Key
	-Composite Key- Partition Key+Sort Key
-Each item can be upto 400kb 
-Data Consistency
	-Eventually Consistent -Default
	-Strongly Consistent

*DynamoDb Access Control
-Using IAM we can give specific permissions to dynamodb tables.
-Using IAM Roles we can give temp access to specific user for a single item in a table.
-dyanamodb:LeadingKeys allows users to acces only items where partition key value matches user id.

*Indexes
-DyanamoDb allows to run flexible quering(Quering using non primary attributes) using Local Secondary indexes and Global Secondary Indexes
-Local Sec Indexes can be created only while creating the table.Same partition key as original table and different sort key.
-Global Sec Indexes can be anytime with different partition key and different sort key.WCU/RCU must be same or more the primary table

*SCAN vs QUERY
-Scan
 -Dumps out entire tables and filters out the unwanted items.
 -ProjectionExpression Paremeter can be used 
 -As the tables grows scan takes more time

-Query
 -Can be queried using primary key to get a specific or required items.
 -ProjectionExpression parameter can be used to get only required attributes.
 -Eventually consistent by default can be set to strongly consistent.
 -More efficient then scan
 -Results are sorted using sort key
 -By default ascending order , can set ScanIndexForward to false change the order.

*DynamoDb API calls
	-create-table - CreateTable - creates new table
	-put-item - PutItem -adds/replace an item
	-get-item - GetItem
	-update-item - UpdateItem
	-update-table - UpdateTable
	-list-tables - Listtables
	-describe-table-DescribeTable
	-scan-Scan
	-query -Query
	-delete-item - DeleteItem
	-delete-table - DeleteTable

these commands uses these API calls to process the request also must have valid IAM permissions.

*DynamoDB Provisioned Throughput
-Measured in Capacity Units - CU
-While createing a table we can specify the requirements in terms of Read CU and Write CU
-1 WCU = 1*1Kb write per second
-1 RCU = 2*4kb Eventually consitence reads per second 1*4kb strongly consitence reads per sec

*DynamoDB On Demand Capacity - It scales up or down instantly based on application and charges do apply best for upredictable worloads, Provisioned capacity is best suited when workload is properly known and charges are in control.

*DynamoDB Streams
-Time ordered sequence of item level modification.
-Record these action in a log . stored for 24hrs only and encrypt at rest.
-Can be used as a event source for lambda function.


*DynamoDB TTL
-Defines an expiry time for the data
-Marked Items are going to delete in next 48hours
-Expiry time will be expressed in epoch time



*DAX
-Fully managed in memory cache for dynamodb
-Increases the performace only for the read performance up to 10x
-Good for ready heavy workloads.

*Provisioned Throughput and Exponential backoff
-High rate of read and write , and exceeds provisioned capacity
-If you are using AWS SDK it will retry until successfull else have to configure exponential backoff.
-Reduce the frequency./use exp back off






Monitoring
=======================


Other Services
=======================
*SQS-Simple Queue Service
-Queue is a temporary repository for messages awaiting processing.

-EC2 instances will poll the queue

-Scenario- Meme Website - User uploads a photo to S3 bucket - triggers lambda function which gets all information and be avaialble in message queue in SQS - EC2 will poll from SQS to add any text/ any other task and store it back to S3.

-Visibility timeout- when a message is picked by one ec2 instance from SQS that msg becomes invisible and not available for other instances.That time period is called visibility timeout. This is the time that application server gets to process the message.If the message is not processed in within the time then it will be returned to queue and will be picked by other application server to process.

-SQS will help to decouple the infrastructure, as all messages will not be lost until its get processed and reduce inter dependencies between components of an application

-Messages can contain upto 256kb of text in any format.xml,plaintext/json etc

-SQS acts as a buffer between 2 components

-Resolves Scheduling issue.

/***
Key Points - 1. Pull Based 2. 256Kb of any format text data 3.Messages will be processed at least once 4. Msgs can be kept in queue from 1 minute to 14 days. 5.default retention period is 4days. 6.Distributed message queueing system allows to decouple the components of application.
***/

*SQS Queue types
-Standard Queue
	-Defualt ,which provides best effort ordering
	-Unlimited no.of transcations/per second
	-Gurantees that Msg will be delivered atleast once
-FIFO Queue
	-Ordering is strictly prserved
	-300 Transactions per second
	-Exactly once processing
	-No Duplicates are introduced and available until customer processess.

*


*SNS-Simple Notification service
*SES- Simple Email Service
*Kinesis
-
-
-
-
-

*Elastic Beanstalk



Encryption
=======================
*KMS
-Create and Manage encrpytion keys.
-Integrated with loads of serives.
-

*CMK-Customer Master Key
-Encrypt /decrypt data upto 4kb
-Generate/encypt/decrypt data key
-data key encrypts the data and CMK encrypts the data key.This is called envolupe Encryption.


*Cerificate Management in AWS
-Service that allows to create and manage public and private Secure Sockets Layer (SSL) /TLS-Transport Layer Security certificates.
-Can be used with other services.
-SSL/TLS certificate is a digital certificate that are used to verify the authenticity of a website. which enable secure connection between website and user.Also used to encrypt data in transit.
-If ACM is going to use with cloudfront only we can use in US-EAST-1 region.


Serverless
=======================
-Allows to run code on cloud with managing infrastructure.
-Serverless architecture are Event driven and asynchronous
-Can use AWS services as building blocks to build serverless architecture. they are loosely coupled.
*Lamda
-Serverless compute. 
-Includes all Enterprise featiures
-Its event driven , can be triggered by actiion of other services.
*Version Control with lambda
-When we create lambda function that is attached with name $LATEST, which is latest code .
-Alias is just like a pointer points to specific version of a code.
*Lambda Concurrent Executions Limit
-Default is 1000 concurrent execution per second per  region . If crosses hits 429 HTTP status code.
-Can increase by requesting to AWS support center. 
-Reserved concurrency gurantees a set of number of concurrent executions are always available to critical fuction.
*Lambda and VPC access
-By default, if lambda wants to communicate with the resources inside private Subnet/VPC its not allowed.
-VPC configuration needs to be done.
-details-Specify the VPC,Select the subnet that lambda going to use, choose security group that requires access.

*Step Functions- Provides a visual interface for serverless applications which enables to build and run serverless aps as a series of steps.
-Consists of State Machine and tasks , State machine is workflow itself and task is each step.
-Sequential workflows
-Parallel Workflows
-Branching workflows

*Comparing Step Function Workflows
-Standard workflows-
 -Long running- durable and auditable that may run up for up to a year.full execution history will beavailable upto 90 days after completion.
 -AT-MOST-ONCE Model-  Tasks are never run more than once until explicitly specify retry action.
 -Non Idempotent Actions - When Processing payments,Only want to be processed once.(non idempotent-Always causes change in state)

-Express workflows
 -Short Lived-Upto 5 minutes,great for high vloume, event-processing-type type workloads.
 -AT-Least-Once - Ideal if there is a possibility that an execution might be run more than once.or require concurrent execution
 -Idempotent - (If the same action is performend several times there will be no side effects in the state)
-2 Types of Express workflows
	-Sync-begins workflow, waits until wf completes,returns the result. Great for operation performed one at a time. Workflow must complete before next step begins.
	-Async-Begins workflow,confirms wf has started, the results can be found in Cloudwatch logs. Great if operation doesnot depends on completion and result of workflow



*Understanding Ephemeral & Prsistent data Storage patterns.
- Lambda is Stateless-Functions are stateless meaning that you can not permanently store any data in the function.(ex. session data, customer data)
- Lambda is Ephemeral - only run for short period of time, not used for application that run more than 15 min.
- To presist data the function must interact with data stores like s3,efs,dynamodb
-Lambda Data storing options-
 - Native with Lambda- /temp, lambda layers
	-/temp - Temporary storage , provided in the execution environment of lambda function.By defualt 512 MB , configurable up to 10 gb.
	       - Like  a chaced file system
 	       - Data is not persistant- Available for lifetime of execution env, not a permanent place to store data
	-lambda Layers - Add libraries and SDK's as a layer that can be refrenaced by multiple funtions. Deployment will be faster as dependeancies are in different layer.50MB zipped -250MB unzipped
 -External storage - s3, efs etc
	-S3- Object store only not files.
	   - Cannot diretly open and write data to objects in S3.If data needs to be changed completely new object should be uploaded.
	-EFS-shared file system, data is persistant and can dynamically be updated.
	    - EFS needs to be mounted by funtion when execution env is created.can be shared across invocations
	    - To use EFS lambda function must be in same VPC as EFS

*Environment Variables.
-Its a configurable parameter in Lambda, These helps to adjust the behaviour of function without changing the code.Its is basically a key value pair.
-Locked when the version is published.
-Other Configurable Parameters in Lambda - VPC, Tags,General Configurations, Triggers, Permissions, function URL, Monitoring and Operations Tools , Concurency, File systems.

*lambda Invocations -
	-Sync -runs, wait for response and return response
	-Async- No acknowledgement that function completed.
-How do we handle error in case of Async Invocation?
-Lambda Retries- If funtion returns an error , automatically performs two retries.Lambda waits for one minute before first retry, 2 min before second retry.
 -Common Errors-Something went wrong in function, function timed out.
-Dead Letter Queues
 -Save failed invocations for further processing, asociated with perticular version of function, can be an event source for a function allowing reprocess.No invocation records will be sent.
-Lambda Destinations
 -Configure one destinantion successful invocation records and other unsucessfull invocation.Invocation records will be sent.

*Lambda Deployment Packaging Options
-When we write a function code in lambda, automatically a .zip file is created in background.This Zip file is deployment package. .zip=application code+dependencies(optional)
-Also we can create deployment package ourself and upload directly from local up to 50MB.
-If Deployment package is greater than 50MB, Then need to upload file to s3 in the same region where we create funtion.specify that object when create a function.
-We can use lambda layers for libraries and other dependecies and SDKs, A layer can be used by many functions.

*Lambda Performance Tuning Best Practises-
-Increasing memory will increase CPU which reduce the duration.
-Imporing libraries and SDKs can take time only import what we need 

*Lambda Destinantions and Dead Letter Queues


*API Gateway
-Serverless, cost effective and scalable.
-Its like a front door to the application.
- We can import our own API to API gateway using import API feature using definition file.
-Protocol that supports to import is OpenAPI formerely known as Swagger.
-We can use OpenAPI definition file to create a new API or updating an existing API.
-Legacy Protocols-SOAP-returns XML.
-When using legacy protocol,can configure API Gateway as a SOAP web service passtrough, or you can use API Gateway to convert the XML response to JSON.

*API Gateway Mock endpoints
-Allows developers to create,test and debug software.
-Mimics the responses and behaviour of real API.
-Allows to simulate responses and behaviour which we expect from real API.Also described as mock integration.

*API Gateway Stages
-referances the lifecycle state of the API.
-also can use stage variables jus like environment variable to change behaviour of API

-API Gateways can transform request and responses using parameter mapping.

*API Gateway Chaching
-This reduces number of calls made by aslo improves latency, responses cached for 300 seconds
-By default API Gateway limits the steady state request rate to 10000 req/sec/region, concurrent 5K/across all api/region, can request in increase.



*X-Ray
-Helps developers to analyze and debug distributed application.
-Provides a visualizztion of application components.which is called x-ray service Map.
-In order x-ray to work with application, Install the X-ray agent, configure using X-ray SDK.
-X-Ray SDK to X-Ray Daemon to X-Ray in bacthes.
-So X-Ray SDK and Daemon must be installed in system to send data to x-ray
-For On premises and EC2 - Install Daemon on server
-For Elastic Beanstalk- Install X-Ray Daemon on EC2 instances inside elastic Beanstalk.
--For Docker - Install Daemon on same cluster as app.












Developer Theory
========================
*CodeCommit
*CodeBuild
*CodeDeploy
*CodePipeline
*CodeArtifact
*CloudFormation
*CDK
*Amplify




